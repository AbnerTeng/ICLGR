# Axolotl config for MSMarco ICL training
# Training the model to learn document indexing and query-to-doc_id retrieval

base_model: Qwen/Qwen3-1.7B-Base

# Dataset configuration
datasets:
  - path: ./data/msmarco_axolotl/train.jsonl
    type: chat_template
    
    # Use tokenizer's chat template
    chat_template: tokenizer_default_fallback_chatml
    
    # Field mappings
    field_messages: conversations
    message_property_mappings:
      role: role
      content: content
    
    # Role configuration
    roles:
      assistant:
        - assistant
      user:
        - user
      system:
        - system
    
    # Train only on assistant responses
    roles_to_train: ["assistant"]
    train_on_eos: "turn"

# Streaming for large datasets
streaming: false  # Set to true if memory is limited
shuffle_merged_datasets: true

# Training configuration
output_dir: ./checkpoints/msmarco-icl
sequence_len: 2048
sample_packing: true
pad_to_sequence_len: true
flash_attention: true

# Batch and gradient settings
gradient_accumulation_steps: 8
micro_batch_size: 4
num_epochs: 3

# Optimizer
optimizer: adamw_8bit  # or adamw_torch for more precision
lr_scheduler: cosine
learning_rate: 2.0e-5
warmup_ratio: 0.05
weight_decay: 0.01

# Precision
bf16: auto
tf32: false
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false

# Logging
logging_steps: 10
save_strategy: steps
save_steps: 500
save_total_limit: 3

# Evaluation
eval_strategy: steps
eval_steps: 500
val_set_size: 0.01  # Use 1% of train for validation

# Special tokens
special_tokens:
  eos_token: "<|im_end|>"

# Weights & Biases (optional)
wandb_project: msmarco-icl
wandb_entity: null
wandb_name: msmarco-icl-qwen3-1.7b
wandb_log_model: false

# LoRA configuration (optional - uncomment to use LoRA instead of full finetuning)
# adapter: lora
# lora_r: 32
# lora_alpha: 16
# lora_dropout: 0.05
# lora_target_modules:
#   - q_proj
#   - v_proj
#   - k_proj
#   - o_proj
#   - gate_proj
#   - down_proj
#   - up_proj

# Early stopping (optional)
# early_stopping_patience: 3
